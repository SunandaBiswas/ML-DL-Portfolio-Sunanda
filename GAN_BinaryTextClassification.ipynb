{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "- reading materials https://developers.google.com/machine-learning/gan/gan_structure\n"
      ],
      "metadata": {
        "id": "CdqjooVFCZSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW8qXRgoEBQ_",
        "outputId": "e8141cff-93c4-4d2f-cc54-17a52eedef6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aZlcw0mxCXtz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('fake.csv')\n",
        "\n",
        "# If label column isn't present, assign label 0 (fake)\n",
        "if 'label' not in df.columns:\n",
        "    df['label'] = 0  # Assume all fake.csv entries are fake news\n",
        "\n",
        "# Drop rows with missing text\n",
        "df = df.dropna(subset=['text'])\n",
        "\n",
        "# Use a subset for faster training (optional)\n",
        "df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Vectorize text using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "X = vectorizer.fit_transform(df['text']).toarray()\n",
        "y = df['label'].values  # Binary labels (0 = fake, 1 = real)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes + 1)  # 2 real classes + 1 fake class\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "NsMxIRHoFC_9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "noise_dim = 100\n",
        "input_dim = X_train.shape[1]\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "# Initialize models and optimizers\n",
        "gen = Generator(noise_dim, input_dim)\n",
        "disc = Discriminator(input_dim)\n",
        "g_opt = optim.Adam(gen.parameters(), lr=0.001)\n",
        "d_opt = optim.Adam(disc.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    permutation = torch.randperm(X_train.size(0))\n",
        "\n",
        "    for i in range(0, X_train.size(0), batch_size):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        real_data = X_train[indices]\n",
        "        real_labels = y_train[indices]\n",
        "\n",
        "        b_size = real_data.size(0)\n",
        "\n",
        "        # ---- Train Discriminator ----\n",
        "        z = torch.randn(b_size, noise_dim)\n",
        "        fake_data = gen(z).detach()\n",
        "\n",
        "        real_output = disc(real_data)\n",
        "        fake_output = disc(fake_data)\n",
        "\n",
        "        # real class = 0 or 1, fake class = 2\n",
        "        real_targets = real_labels\n",
        "        fake_targets = torch.full((b_size,), 2, dtype=torch.long)\n",
        "\n",
        "        d_loss_real = criterion(real_output, real_targets)\n",
        "        d_loss_fake = criterion(fake_output, fake_targets)\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "        d_opt.zero_grad()\n",
        "        d_loss.backward()\n",
        "        d_opt.step()\n",
        "\n",
        "        # ---- Train Generator ----\n",
        "        z = torch.randn(b_size, noise_dim)\n",
        "        gen_data = gen(z)\n",
        "        d_output = disc(gen_data)\n",
        "\n",
        "        # Try to fool discriminator: assign real labels randomly (0 or 1)\n",
        "        g_targets = torch.randint(0, 2, (b_size,))\n",
        "        g_loss = criterion(d_output, g_targets)\n",
        "\n",
        "        g_opt.zero_grad()\n",
        "        g_loss.backward()\n",
        "        g_opt.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vEkAFn4FG2k",
        "outputId": "f88ec65d-87e1-4653-baa8-8bdb8d2d819c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], D Loss: 0.5323, G Loss: 3.0236\n",
            "Epoch [2/10], D Loss: 1.1239, G Loss: 2.6370\n",
            "Epoch [3/10], D Loss: 1.2781, G Loss: 2.9823\n",
            "Epoch [4/10], D Loss: 0.9044, G Loss: 2.9824\n",
            "Epoch [5/10], D Loss: 1.2207, G Loss: 3.1507\n",
            "Epoch [6/10], D Loss: 0.8147, G Loss: 3.5550\n",
            "Epoch [7/10], D Loss: 0.6960, G Loss: 3.4037\n",
            "Epoch [8/10], D Loss: 0.4785, G Loss: 3.8445\n",
            "Epoch [9/10], D Loss: 0.8068, G Loss: 4.9976\n",
            "Epoch [10/10], D Loss: 0.8279, G Loss: 4.4811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    test_output = disc(X_test)\n",
        "    preds = torch.argmax(test_output[:, :2], dim=1)\n",
        "    acc = (preds == y_test).float().mean()\n",
        "    print(f\"\\n🎯 Test Accuracy: {acc.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RDCdK6TFKDN",
        "outputId": "3f6a51a8-02e3-46a8-a3b7-01e2c6a78b39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check Results"
      ],
      "metadata": {
        "id": "bm1kd0spGwQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Function to classify a single news article\n",
        "def classify_random_article(gen, disc, vectorizer, filepath='fake.csv'):\n",
        "    import pandas as pd\n",
        "    import torch\n",
        "\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    if 'label' not in df.columns:\n",
        "        df['label'] = 0  # All samples from fake.csv assumed fake\n",
        "\n",
        "    # Drop rows with missing text\n",
        "    df = df.dropna(subset=['text']).reset_index(drop=True)\n",
        "\n",
        "    # Pick a random sample\n",
        "    idx = random.randint(0, len(df) - 1)\n",
        "    text = df.loc[idx, 'text']\n",
        "    true_label = df.loc[idx, 'label']\n",
        "\n",
        "    # Vectorize the text using the same TF-IDF vectorizer\n",
        "    text_vector = vectorizer.transform([text]).toarray()\n",
        "    text_tensor = torch.tensor(text_vector, dtype=torch.float32)\n",
        "\n",
        "    # Get prediction from discriminator\n",
        "    disc.eval()\n",
        "    with torch.no_grad():\n",
        "        output = disc(text_tensor)\n",
        "        pred_class = torch.argmax(output[:, :2], dim=1).item()\n",
        "\n",
        "    label_map = {0: 'Fake', 1: 'Real'}\n",
        "    print(\"📰 Random News Article:\")\n",
        "    print(\"-----------------------------------------------------\")\n",
        "    print(text[:1000] + (\"...\" if len(text) > 1000 else \"\"))\n",
        "    print(\"-----------------------------------------------------\")\n",
        "    print(f\"✅ Predicted Class: {label_map[pred_class]}\")\n",
        "    print(f\"🎯 True Label: {label_map[true_label]}\")\n",
        "\n",
        "# ⚠️ Call this only after training. It uses the trained `disc`, `vectorizer`.\n",
        "classify_random_article(gen, disc, vectorizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFcYzw3wGasK",
        "outputId": "e8a31516-1b31-43c6-95aa-331716f627b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📰 Random News Article:\n",
            "-----------------------------------------------------\n",
            "Obama made Wall Street out to be the enemy during his presidency. He bashed them on one hand then supported them with the other Speaking out of both sides of his mouth is a true talent Obama has. He counts on the people to forget and forgive his misdeeds and they do. Who else could get away with so many lies? Remember when he called Wall Street every bad name in the book? Fat Cats?He also said,  At some point you ve made enough money We d like to know what  enough money  means to Obama who s taking 400K for his speech at a Cantor Fitzgerald event in September. We think it s time for Obama to practice what he preaches and  spread the wealth . It s only fair, right?OBAMA WANTS TO GET IN ON THE ACT THE CLINTONS HAVE BEEN DOING FOR DECADES   BIG MONEY SPEECHES ARE THEIR BREAD AND BUTTER: OUR PREVIOUS REPORT ON SPEECHES THE CLINTONS HAVE GIVEN: Thank God she has a vagina, otherwise her blatant hypocrisy might be an issue with voters Hillary Clinton is facing more questions about her close t...\n",
            "-----------------------------------------------------\n",
            "✅ Predicted Class: Fake\n",
            "🎯 True Label: Fake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify a specific row (by index) from the dataset\n",
        "def classify_article_by_row(gen, disc, vectorizer, row_index, filepath='fake.csv'):\n",
        "    import pandas as pd\n",
        "    import torch\n",
        "\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    # If label not present, assume all fake\n",
        "    if 'label' not in df.columns:\n",
        "        df['label'] = 0\n",
        "\n",
        "    # Drop rows with missing text\n",
        "    df = df.dropna(subset=['text']).reset_index(drop=True)\n",
        "\n",
        "    # Check if row_index is valid\n",
        "    if row_index >= len(df) or row_index < 0:\n",
        "        print(f\"⚠️ Invalid row index {row_index}. Dataset has {len(df)} rows.\")\n",
        "        return\n",
        "\n",
        "    # Get the text and label\n",
        "    text = df.loc[row_index, 'text']\n",
        "    true_label = df.loc[row_index, 'label']\n",
        "\n",
        "    # Vectorize text\n",
        "    text_vector = vectorizer.transform([text]).toarray()\n",
        "    text_tensor = torch.tensor(text_vector, dtype=torch.float32)\n",
        "\n",
        "    # Predict class using the discriminator\n",
        "    disc.eval()\n",
        "    with torch.no_grad():\n",
        "        output = disc(text_tensor)\n",
        "        pred_class = torch.argmax(output[:, :2], dim=1).item()\n",
        "\n",
        "    label_map = {0: 'Fake', 1: 'Real'}\n",
        "    print(f\"📰 News Article at Row {row_index}:\")\n",
        "    print(\"-----------------------------------------------------\")\n",
        "    print(text[:1000] + (\"...\" if len(text) > 1000 else \"\"))\n",
        "    print(\"-----------------------------------------------------\")\n",
        "    print(f\"✅ Predicted Class: {label_map[pred_class]}\")\n",
        "    print(f\"🎯 True Label: {label_map[true_label]}\")\n",
        "\n",
        "# 🔍 Example usage:\n",
        "# Get classification result for row 10 (change to any index you want)\n",
        "classify_article_by_row(gen, disc, vectorizer, row_index=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAjGmXiJIRvn",
        "outputId": "80cf6608-6008-4adb-8431-c3d284b88150"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📰 News Article at Row 10:\n",
            "-----------------------------------------------------\n",
            "A centerpiece of Donald Trump s campaign, and now his presidency, has been his white supremacist ways. That is why so many of the public feuds he gets into involve people of color. One of his favorite targets, is, of course, the players in the National Football League who dare to exercise their First Amendment rights by kneeling during the national anthem in protest of racist police brutality. Well, there is one person who has figured out that racism is bad for business, even if it did get the orange overlord elected: The founder of the pizza chain Papa John s.This is a man who has never been on the right side of history on any number of issues, and plus his pizza sucks. But, when he decided to complain about the players protesting, his sales really dropped. Turns out racism doesn t pay, and we all know that corporations are all about the bottom line. Therefore, Papa John Schnatter will no longer be CEO of the hack pizza chain.BREAKING: Papa John's founder John Schnatter to step down a...\n",
            "-----------------------------------------------------\n",
            "✅ Predicted Class: Fake\n",
            "🎯 True Label: Fake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get classification result for row 100 (change to any index you want)\n",
        "classify_article_by_row(gen, disc, vectorizer, row_index=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJmYH6ODI3gn",
        "outputId": "cae27876-08b2-4f2d-a26b-68056b10b614"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📰 News Article at Row 100:\n",
            "-----------------------------------------------------\n",
            "Former Vice President Joe Biden was asked on Monday by Matt Lauer on NBC s  Today  to name something specific that Donald Trump has been  doing well. Well, that seems like a trick question since Trump has passed no major legislation and reaches across the aisle only to take shots at Democrats in his Twitter timeline during his morning rage-tweets, so Biden struggled to find something, anything, that Trump has done well since taking office. I think there s a number of things he s doing well. But even the things he s doing well, it s how he does them,  Biden said. It s more the tone of this administration that bothers me,  he continued. With all due respect, you haven t come up with one thing you think he s doing well,  Lauer said. Well, I think he married very well,  Biden joked.Although, Biden didn t mention which of Trump s three marriages he s speaking of. Trump s first marriage to Ivana ended after he had an affair with Marla Maples. Trump went on to marry Maples, then they divorced...\n",
            "-----------------------------------------------------\n",
            "✅ Predicted Class: Fake\n",
            "🎯 True Label: Fake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get classification result for row 123 (change to any index you want)\n",
        "classify_article_by_row(gen, disc, vectorizer, row_index=123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXtO8Fs9I7gr",
        "outputId": "2287f9d3-0c66-4a84-d134-b14fe3fcbb7f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📰 News Article at Row 123:\n",
            "-----------------------------------------------------\n",
            "Long before Cara Mund,  Miss North Dakota,  won the 2018 Miss America pageant, she faced a crowd of 50 other young women, all competing in various categories for the coveted crown. Two of those categories, to most of our readers, are patriarchal and silly: The evening wear and swimwear  competitions  pit all these beautiful young women against one another for assessment on their looks by a panel of judges.The other two categories, however, can be quite interesting, especially when something happens like what went down with Miss Texas in this year s competition.The talent portion of the show is, of course, just plain entertaining. Perhaps you ve seen the movie Miss Congeniality, starring Sandra Bullock, and if you have, you know what I m hoping to see in a talent show. The real thing is very little like that, however, and so is the interview portion of Miss America. Source: Meme Central, a folder on my computerTonight, Miss Texas was no Miss Rhode Island. There were two rounds of questi...\n",
            "-----------------------------------------------------\n",
            "✅ Predicted Class: Fake\n",
            "🎯 True Label: Fake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LUx3iK4ZJE7o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}